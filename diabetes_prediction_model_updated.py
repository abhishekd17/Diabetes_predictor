# -*- coding: utf-8 -*-
"""Diabetes Prediction Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eIE0JqDeViSL3She2F24H1hd5TqCIT8B
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix , ConfusionMatrixDisplay
from sklearn.metrics import precision_score , recall_score , f1_score
from sklearn.metrics import classification_report
import pickle

dataset = pd.read_csv('/content/diabetes (1).csv')

dataset.head()

dataset.tail()

dataset.shape

dataset.describe()

dataset['Outcome'].value_counts()

dataset.groupby('Outcome').mean()

X = dataset.drop(columns='Outcome' , axis=1)
Y = dataset['Outcome']

print(X)

print(Y)

scaler = StandardScaler()

scaler.fit(X)

std_data = scaler.transform(X)

print(std_data)

X = std_data
Y = dataset['Outcome']

print(X)

print(Y)

X_train , X_test , Y_train , Y_test = train_test_split(X , Y , test_size = 0.2 , stratify = Y , random_state = 2 )

print(X_test.shape , X_train.shape , X.shape)

classifier = svm.SVC(kernel = 'linear')

classifier.fit(X_train , Y_train)

X_train_prediction = classifier.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction , Y_train)

print("Accuracyb Score of the training data is : " ,training_data_accuracy )
print('In percentage : {:.2f} %'.format(training_data_accuracy * 100))

X_test_prediction = classifier.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction , Y_test)

print('Accuracy score of the testing data : ' , test_data_accuracy )
print('In percentage : {:.2f} %'.format(test_data_accuracy * 100))

input_data = (5,166,72,19,175,25.8,0.587,51)

input_data_as_numpy_array = np.asarray(input_data)

input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

std_data = scaler.transform(input_data_reshaped)

print(std_data)

prediction = classifier.predict(std_data)

print(prediction)

if (prediction[0] == 0):
  print('The person is not diabetic')
else:
  print('The person is diabetic')

cm = confusion_matrix(Y_test , classifier.predict(X_test))
display = ConfusionMatrixDisplay(cm)
display.plot()
plt.show()

from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score

cm = confusion_matrix(Y_test, classifier.predict(X_test))

# Extract True Positives, False Positives, False Negatives, and True Negatives
TP = cm[1, 1]
FP = cm[0, 1]
FN = cm[1, 0]
TN = cm[0, 0]

# Calculate Precision
precision = TP / (TP + FP) if (TP + FP) != 0 else 0

# Calculate Recall
recall = TP / (TP + FN) if (TP + FN) != 0 else 0

# Calculate F1 Score
f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0

print('Precision:', precision)
print('Recall:', recall)
print('F1 Score:', f1)
print()
# Alternatively, can use sklearn's built-in functions
y_pred = classifier.predict(X_test)
print('Precision (sklearn):', precision_score(Y_test, y_pred))
print('Recall (sklearn):', recall_score(Y_test, y_pred))
print('F1 Score (sklearn):', f1_score(Y_test, y_pred))

y_pred = classifier.predict(X_test)
report = classification_report(Y_test, y_pred)
print(report)



"""Using differnet Algorithms"""

from sklearn.linear_model import LogisticRegression

up_classifier = LogisticRegression()

up_classifier.fit(X_train , Y_train)

X_train_prediction_up = up_classifier.predict(X_train)
training_data_accuracy_logistic = accuracy_score(X_train_prediction_up , Y_train)

print('Accuracy score of the training data : ' , training_data_accuracy_logistic )
print('In percentage : {:.2f} %'.format(training_data_accuracy_logistic * 100))

x_test_prediction_logistic = up_classifier.predict(X_test)
test_data_accuracy_logistic = accuracy_score(x_test_prediction_logistic , Y_test)

print('Accuracy score of the testing data : ' , test_data_accuracy_logistic )
print('In percentage : {:.2f} %'.format(test_data_accuracy_logistic * 100))

cm_up = confusion_matrix(Y_test, up_classifier.predict(X_test))
disp = ConfusionMatrixDisplay(confusion_matrix=cm_up)
disp.plot()
plt.show()

from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score

cm_up = confusion_matrix(Y_test, up_classifier.predict(X_test))

# Extract True Positives, False Positives, False Negatives, and True Negatives
TP = cm_up[1, 1]
FP = cm_up[0, 1]
FN = cm_up[1, 0]
TN = cm_up[0, 0]

# Calculate Precision
precision = TP / (TP + FP) if (TP + FP) != 0 else 0

# Calculate Recall
recall = TP / (TP + FN) if (TP + FN) != 0 else 0

# Calculate F1 Score
f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0

print('Precision:', precision)
print('Recall:', recall)
print('F1 Score:', f1)
print()
# Alternatively, can use sklearn's built-in functions
y_pred = up_classifier.predict(X_test)
print('Precision (sklearn):', precision_score(Y_test, y_pred))
print('Recall (sklearn):', recall_score(Y_test, y_pred))
print('F1 Score (sklearn):', f1_score(Y_test, y_pred))

from sklearn.metrics import classification_report

y_pred = up_classifier.predict(X_test)
report = classification_report(Y_test, y_pred)
print(report)

